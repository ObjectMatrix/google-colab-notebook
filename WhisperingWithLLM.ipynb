{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1tIijdVBbXy3Q0RYNnGd43dotzG2bOTN-",
      "authorship_tag": "ABX9TyPOx0VyaySoOAsO8/XuIdr+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ObjectMatrix/google-colab-notebook/blob/main/WhisperingWithLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual Transcription: see [Ren's Wiki](https://libertymutual.atlassian.net/wiki/spaces/~62fefff51e82e839c250dcae/blog/2023/06/22/835472240/PA+university+video+parts+summary) for detail notes on PA University Video Summary\n",
        "\n",
        "Following is an attempt to automate the whole process **with Whisper and LLM**"
      ],
      "metadata": {
        "id": "Sp7ZaEsmkWsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dependencies**"
      ],
      "metadata": {
        "id": "d0AauoWomvUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "96LEWZYhCfI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01859469-076d-423c-d782-f1e54b230d6a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdE-aZCyecV9"
      },
      "outputs": [],
      "source": [
        "# !pip install -q pytube\n",
        "!pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install tiktoken==0.3.3\n",
        "\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "# from pytube import YouTube\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import get_writer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !whisper \"/content/drive/MyDrive/mp4/PAU_Session1_P1_Feb2021.mp4\" --model medium.en"
      ],
      "metadata": {
        "id": "x_oMCzaqf4yw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file=\"/content/drive/MyDrive/mp4/PAU_Session1_P1_Feb2021.mp4\"\n",
        "file_path = Path(file)\n",
        "print(f\"Transcribing file: {file_path}\\n\")\n",
        "output_directory = file_path.parent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IVgaBDlnrwN",
        "outputId": "5282970d-3176-453e-9f84-3c7aceb303a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing file: /content/drive/MyDrive/mp4/PAU_Session1_P1_Feb2021.mp4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use CUDA, if available\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the desired model\n",
        "model = whisper.load_model(\"medium.en\").to(DEVICE)\n"
      ],
      "metadata": {
        "id": "QHVeGAeZmXAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23684498-d83d-4587-8bf2-0494014179b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:17<00:00, 85.4MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✍ Transcribing with Whisper"
      ],
      "metadata": {
        "id": "-uAHMPtGqXRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_file(model, file, plain=None, srt=None, vtt=None, tsv=None, download=None):\n",
        "    file_path = Path(file)\n",
        "    print(f\"Transcribing file: {file_path}\\n\")\n",
        "\n",
        "    output_directory = file_path.parent\n",
        "\n",
        "    # Run Whisper\n",
        "    result = model.transcribe(file, verbose = False, language = \"en\")\n",
        "    txt_path = file_path.with_suffix(\".txt\")\n",
        "    print(f\"\\nCreating text file\")\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "      txt.write(result[\"text\"])\n",
        "\n",
        "    # here is more fomalization for any types\n",
        "    if plain:\n",
        "        txt_path = file_path.with_suffix(\".txt\")\n",
        "        print(f\"\\nCreating text file\")\n",
        "\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "            txt.write(result[\"text\"])\n",
        "    if srt:\n",
        "        print(f\"\\nCreating SRT file\")\n",
        "        srt_writer = get_writer(\"srt\", output_directory)\n",
        "        srt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if vtt:\n",
        "        print(f\"\\nCreating VTT file\")\n",
        "        vtt_writer = get_writer(\"vtt\", output_directory)\n",
        "        vtt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if tsv:\n",
        "        print(f\"\\nCreating TSV file\")\n",
        "\n",
        "        tsv_writer = get_writer(\"tsv\", output_directory)\n",
        "        tsv_writer(result, str(file_path.stem))\n",
        "\n",
        "    if download:\n",
        "        from google.colab import files\n",
        "\n",
        "        colab_files = Path(\"/content\")\n",
        "        stem = file_path.stem\n",
        "\n",
        "        for colab_file in colab_files.glob(f\"{stem}*\"):\n",
        "            if colab_file.suffix in [\".txt\", \".srt\", \".vtt\", \".tsv\"]:\n",
        "                print(f\"Downloading {colab_file}\")\n",
        "                files.download(str(colab_file))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "kIJ4TcMsodEC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "💬 Whisper it This block calls transcribe_file 😉"
      ],
      "metadata": {
        "id": "LfCuLoNhrKe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if input_format == \"youtube\":\n",
        "#     # Download the audio stream of the YouTube video\n",
        "#     print(f\"Downloading audio stream: {audio}\")\n",
        "#     audio = download_youtube_audio(file)\n",
        "\n",
        "#     # Run Whisper on the audio stream\n",
        "#     result = transcribe_file(model, audio, plain, srt, vtt, tsv, download)\n",
        "# elif input_format == \"gdrive\":\n",
        "#     # Authorize a connection between Google Drive and Google Colab\n",
        "#     from google.colab import drive\n",
        "#     drive.mount('/content/drive')\n",
        "\n",
        "#     # Run Whisper on the specified file\n",
        "#     result = transcribe_file(model, file, plain, srt, vtt, tsv, download)\n",
        "# elif input_format == \"local\":\n",
        "    # Run Whisper on the specified file\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/MyDrive/mp4')\n",
        "\n"
      ],
      "metadata": {
        "id": "I26S0eT-p9E9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do not run folloing if already audio text is acquired from the given videos"
      ],
      "metadata": {
        "id": "-Io_s7sKJrqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# result = transcribe_file(model, file)"
      ],
      "metadata": {
        "id": "W7tWHdm4JnuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets evaluate rouge_score langchain"
      ],
      "metadata": {
        "id": "LJW9NZ3IDXNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "drive_mount_path = '/content/drive'\n",
        "\n",
        "# Check if the drive is already mounted\n",
        "if not os.path.ismount(drive_mount_path):\n",
        "    from google.colab import drive\n",
        "    drive.mount(drive_mount_path)\n",
        "else:\n",
        "    print(\"Drive is already mounted.\")\n",
        "with open('/content/drive/MyDrive/secrets.json', 'r') as f:\n",
        "  secrets = json.load(f)\n",
        "KEY=secrets['hug_read']\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3jkGBXZE0jq",
        "outputId": "913e77b1-fb16-4430-8876-7730d6e42c6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive is already mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZE9Oire9DwJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163f5793-fff1-4122-9450-7962d87b09f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "LOCAL_DRIVR = '/content/drive/MyDrive/mp4'\n",
        "MY_FILE=LOCAL_DRIVR+\"/PAU_Session1_P1_Feb2021.txt\"\n",
        "\n",
        "def loadTXTFileFromLocal(fileName=MY_FILE):\n",
        "  loader = TextLoader(fileName)\n",
        "  loaded_docs = loader.load()\n",
        "  return loaded_docs"
      ],
      "metadata": {
        "id": "eFz-ChPfEusp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "# summarizer(loadTXTFileFromLocal())\n",
        "\n"
      ],
      "metadata": {
        "id": "6VmmnwqlFZ5T"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}